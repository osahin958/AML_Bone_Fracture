{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55dcd476",
   "metadata": {},
   "source": [
    "# Data Augmentation & Balancing Pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Zielsetzung dieses Notebooks\n",
    "Wie in der explorativen Datenanalyse (EDA) festgestellt wurde, weist der Datensatz ein massives **Klassenungleichgewicht (Class Imbalance)** auf. Häufige Klassen wie *Transverse Displaced* dominieren, während komplexe Frakturen wie *Segmental* oder *Linear* stark unterrepräsentiert sind.\n",
    "\n",
    "Dieses Notebook implementiert eine **Offline-Augmentation-Pipeline**, um dieses Ungleichgewicht vor dem Training zu korrigieren. Ziel ist es, die Anzahl der Trainingsbilder für seltene Klassen synthetisch zu erhöhen (Upsampling), um dem Modell eine statistisch ausgewogene Lernbasis zu bieten.\n",
    "\n",
    "## 2. Technische Umsetzung\n",
    "Die Augmentation erfolgt mithilfe der Bibliothek **Albumentations**, die speziell für Computer Vision Aufgaben optimiert ist und sicherstellt, dass Bounding-Box-Koordinaten bei geometrischen Transformationen korrekt mit angepasst werden.\n",
    "\n",
    "**Verwendete Transformationen:**\n",
    "Um die Varianz der Daten zu erhöhen und das Modell robuster zu machen, werden folgende Techniken kombiniert:\n",
    "*   **Geometrisch:** Horizontales Spiegeln, Rotation, Skalierung, Verschiebung.\n",
    "*   **Pixel-Level:** Anpassung von Helligkeit/Kontrast, Gaußsches Rauschen, Unschärfe (Blur).\n",
    "\n",
    "## 3. Ablauf\n",
    "1.  **Konfiguration:** Definition eines `augmentation_plan`, der festlegt, welche Klasse mit welchem Multiplikator vervielfacht werden soll (z. B. *Segmental* x20).\n",
    "2.  **Pipeline-Definition:** Erstellung der `A.Compose` Pipeline inkl. Bounding-Box-Handling.\n",
    "3.  **Generierung:** Das Skript iteriert über die Originalbilder, wendet die Transformationen an und speichert die neuen Bilder sowie die angepassten Labels (mit Präfix `aug_`) physisch im Trainingsordner.\n",
    "4.  **Bereinigung (Optional):** Eine Hilfsfunktion am Ende erlaubt das schnelle Löschen aller generierten Dateien, um den Ursprungszustand wiederherzustellen.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd59b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der notwendigen Bibliotheken\n",
    "import cv2  # OpenCV: Zum Lesen, Schreiben und Bearbeiten von Bildern\n",
    "import albumentations as A  # Albumentations: Bibliothek für die Bild-Augmentation\n",
    "import os  # os: Für die Interaktion mit dem Betriebssystem, z.B. um auf Dateien und Ordner zuzugreifen\n",
    "import random  # random: Für zufällige Operationen (wird von Albumentations intern genutzt)\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. KONFIGURATION\n",
    "# In diesem Abschnitt werden alle wichtigen Parameter definiert.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Pfade zu den Trainingsdaten ---\n",
    "# Hier geben wir an, wo sich die Bilder und die zugehörigen Label-Dateien befinden.\n",
    "train_img_path = os.path.join('BoneFracturesDetection', 'train', 'images')\n",
    "train_lbl_path = os.path.join('BoneFracturesDetection', 'train', 'labels')\n",
    "\n",
    "# --- Definition der Klassennamen ---\n",
    "# Die Reihenfolge ist entscheidend, da der Index der Liste der Klassen-ID entspricht (z.B. 'Comminuted' == ID 0).\n",
    "class_names = ['Comminuted', 'Greenstick', 'Healthy', 'Linear', 'Oblique Displaced', 'Oblique', 'Segmental', 'Spiral', 'Transverse Displaced', 'Transverse']\n",
    "\n",
    "# --- Augmentations-Plan ---\n",
    "# Wir definieren hier, für welche (seltenen) Klassen wir neue Daten erzeugen wollen\n",
    "# und 'wie viele' neue Bilder für jedes existierende Originalbild dieser Klasse erstellt werden sollen.\n",
    "# Ziel ist es, die Anzahl der Instanzen der seltenen Klassen an die der häufigeren Klassen anzugleichen.\n",
    "augmentation_plan = {\n",
    "    'Segmental': 20,  # Z.B. aus 18 Originalbildern werden ca. 18 * 20 = 360 \n",
    "    'Linear': 20,     # von 21 -> 420\n",
    "    'Oblique': 10,    # von 48 -> 480\n",
    "    'Healthy': 8,     # von 54 -> 432\n",
    "    'Spiral': 8,      # von 66 -> 528\n",
    "    'Greenstick': 5,  # von 81 -> 405\n",
    "    'Transverse': 2,\n",
    "    # Klassen, die hier nicht aufgeführt sind (z.B. 'Transverse Displaced'), werden nicht augmentiert.\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DEFINITION DER AUGMENTATIONS-PIPELINE\n",
    "# Hier legen wir fest, welche zufälligen Veränderungen auf die Bilder angewendet werden sollen.\n",
    "# ==============================================================================\n",
    "\n",
    "# A.Compose erstellt eine Pipeline von Augmentations-Schritten.\n",
    "# Albumentations sorgt dafür, dass die Bounding Boxes korrekt mit-transformiert werden.\n",
    "transform = A.Compose([\n",
    "    # Spiegelt das Bild horizontal mit einer Wahrscheinlichkeit von 50%.\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    \n",
    "    # Ändert zufällig Helligkeit und Kontrast des Bildes.\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    \n",
    "    # Führt zufällig eine Verschiebung, Skalierung und Rotation des Bildes durch.\n",
    "    A.ShiftScaleRotate(shift_limit=0.06, scale_limit=0.1, rotate_limit=15, p=0.7),\n",
    "    \n",
    "    # Fügt dem Bild zufälliges Gaußsches Rauschen hinzu, um es robuster zu machen.\n",
    "    A.GaussNoise(p=0.2),\n",
    "    \n",
    "    # 'OneOf' wendet nur eine der folgenden Transformationen an.\n",
    "    A.OneOf([\n",
    "        A.Blur(blur_limit=3, p=0.5),      # Macht das Bild leicht unscharf.\n",
    "        A.MotionBlur(blur_limit=3, p=0.5), # Simuliert eine Bewegungsunschärfe.\n",
    "    ], p=0.5), # Diese 'OneOf'-Box wird mit einer Wahrscheinlichkeit von 50% ausgeführt.\n",
    "\n",
    "# bbox_params sorgt dafür, dass die Bounding-Box-Koordinaten bei jeder Transformation korrekt mit angepasst werden. 'yolo' gibt das Format an (class_id, x_center, y_center, width, height).\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. DURCHFÜHRUNG DER AUGMENTATION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"--- Starte die Erstellung neuer augmentierter Daten ---\")\n",
    "\n",
    "# --- Zuerst sammeln wir alle Bilder und ordnen sie ihrer Klasse zu ---\n",
    "# Wir erstellen ein Dictionary, um zu speichern, welche Bilddatei zu welcher Klasse gehört.\n",
    "image_class_map = {}\n",
    "for img_file in os.listdir(train_img_path):\n",
    "    # Wir nehmen nur Originalbilder, keine bereits augmentierten.\n",
    "    if img_file.startswith('aug_'):\n",
    "        continue\n",
    "\n",
    "    # Finde die passende Label-Datei zum Bild.\n",
    "    label_file = img_file.replace('.jpg', '.txt').replace('.jpeg', '.txt')\n",
    "    label_path = os.path.join(train_lbl_path, label_file)\n",
    "\n",
    "    # Stelle sicher, dass eine Label-Datei existiert.\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            try:\n",
    "                # Lese die erste Zeile der Label-Datei, um die Klasse zu bestimmen.\n",
    "                # Dies ist eine Vereinfachung; sie funktioniert gut, wenn Bilder meist nur Objekte einer Klasse enthalten.\n",
    "                first_line = f.readline()\n",
    "                if first_line: # Stelle sicher, dass die Datei nicht leer ist\n",
    "                    class_id = int(float(first_line.split()[0])) # Robustes Parsen: erst zu float, dann zu int\n",
    "                    image_class_map[img_file] = class_names[class_id]\n",
    "            except (IndexError, ValueError):\n",
    "                # Ignoriere leere oder fehlerhafte Label-Dateien.\n",
    "                print(f\"Warnung: Konnte Label-Datei {label_file} nicht verarbeiten.\")\n",
    "                continue\n",
    "\n",
    "print(f\"-> {len(image_class_map)} Originalbilder und ihre Klassen wurden eingelesen.\")\n",
    "\n",
    "# --- Jetzt führen wir die eigentliche Augmentation durch ---\n",
    "# Wir gehen durch jedes gefundene Originalbild.\n",
    "for img_file, class_name in image_class_map.items():\n",
    "    # Prüfe, ob die Klasse dieses Bildes in unserem Augmentations-Plan enthalten ist.\n",
    "    if class_name in augmentation_plan:\n",
    "        # Hole die Anzahl der zu erzeugenden neuen Bilder.\n",
    "        num_augmentations = augmentation_plan[class_name]\n",
    "        \n",
    "        # Lade das Originalbild und die zugehörigen Bounding-Box-Daten.\n",
    "        img_path = os.path.join(train_img_path, img_file)\n",
    "        label_path = img_path.replace('images', 'labels').replace('.jpg', '.txt').replace('.jpeg', '.txt')\n",
    "        \n",
    "        # Lade das Bild mit OpenCV.\n",
    "        image = cv2.imread(img_path)\n",
    "        # Konvertiere das Bild vom BGR-Format (OpenCV-Standard) in das RGB-Format (Albumentations-Standard).\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Lese alle Bounding Boxes und Klassen-Labels aus der Label-Datei.\n",
    "        bboxes = []\n",
    "        class_labels = []\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 5:\n",
    "                    class_labels.append(int(float(parts[0])))\n",
    "                    bboxes.append([float(p) for p in parts[1:]])\n",
    "        \n",
    "        # Wenn keine Boxen gefunden wurden, überspringe das Bild.\n",
    "        if not bboxes:\n",
    "            continue\n",
    "\n",
    "        # Erzeuge die festgelegte Anzahl an neuen, augmentierten Bildern.\n",
    "        for i in range(num_augmentations):\n",
    "            # Wende die oben definierte Transformations-Pipeline an.\n",
    "            augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "            \n",
    "            # Erstelle einen neuen, eindeutigen Dateinamen für das augmentierte Bild.\n",
    "            new_img_filename = f\"aug_{class_name}_{i}_{img_file}\"\n",
    "            \n",
    "            # Speichere das neue Bild im Trainingsordner. Konvertiere es zurück ins BGR-Format.\n",
    "            cv2.imwrite(os.path.join(train_img_path, new_img_filename), cv2.cvtColor(augmented['image'], cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "            # Erstelle den passenden Dateinamen für das neue Label.\n",
    "            new_label_filename = new_img_filename.replace('.jpg', '.txt').replace('.jpeg', '.txt')\n",
    "            \n",
    "            # Speichere die transformierten Bounding Boxes im YOLO-Format.\n",
    "            with open(os.path.join(train_lbl_path, new_label_filename), 'w') as f:\n",
    "                for box, label in zip(augmented['bboxes'], augmented['class_labels']):\n",
    "                    # Stelle sicher, dass die Klassen-ID als ganze Zahl (Integer) geschrieben wird.\n",
    "                    f.write(f\"{int(label)} {' '.join(map(str, box))}\\n\")\n",
    "\n",
    "print(f\"\\n--- Augmentation abgeschlossen! ---\")\n",
    "print(f\"Überprüfen Sie die Ordner '{train_img_path}' und '{train_lbl_path}' auf neue Dateien mit dem Präfix 'aug_'.\")\n",
    "print(\"Führe  nun die EDA-Zelle erneut aus, um die neue, ausbalancierte Klassenverteilung zu sehen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "658ce095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lösche alte Augmentations-Dateien...\n",
      "2655 augmentierte Bilder gelöscht.\n",
      "2655 augmentierte Labels gelöscht.\n",
      "Bereinigung abgeschlossen.\n"
     ]
    }
   ],
   "source": [
    "# Löschen der augemntierten Bilder\n",
    "import os\n",
    "\n",
    "train_img_path = os.path.join('BoneFracturesDetection', 'train', 'images')\n",
    "train_lbl_path = os.path.join('BoneFracturesDetection', 'train', 'labels')\n",
    "\n",
    "def cleanup_augmented_files(path, prefix='aug_'):\n",
    "    count = 0\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith(prefix):\n",
    "            os.remove(os.path.join(path, filename))\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(\"Lösche alte Augmentations-Dateien...\")\n",
    "img_deleted = cleanup_augmented_files(train_img_path)\n",
    "lbl_deleted = cleanup_augmented_files(train_lbl_path)\n",
    "print(f\"{img_deleted} augmentierte Bilder gelöscht.\")\n",
    "print(f\"{lbl_deleted} augmentierte Labels gelöscht.\")\n",
    "print(\"Bereinigung abgeschlossen.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML_Sahin (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
